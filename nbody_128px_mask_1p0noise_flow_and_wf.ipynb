{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146b5009-fad1-431f-b8b0-5a256aac54ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import Pk_library as PKL\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utilities\n",
    "import flow_architecture\n",
    "import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb50d8d-e848-4c44-85d8-c756b70965fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "float_dtype = np.float32\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "device_id = 1\n",
    "torch.cuda.set_device(device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ba5420-4056-41cf-8062-b04bc36de001",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"nbody_128px_mask_1p0_flow/\"\n",
    "if not os.path.exists(save_dir): os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e27f6b8-1359-48d2-b6b8-3858b3fe6f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_theo_ell = np.load('sample_test_data/128px_cl_theo_ell.npy')\n",
    "cl_theo = np.load('sample_test_data/128px_cl_theo.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d091ef-11a2-4298-94d8-d59eb3d84004",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameters():\n",
    "    def __init__(self):\n",
    "        #Data parameters\n",
    "        self.nx = 128\n",
    "        self.dx = 0.00018425707547169813\n",
    "        \n",
    "        #Fitting parameters\n",
    "        self.nlev_t = 1.0\n",
    "        self.noise_fac = self.nlev_t\n",
    "        self.noise_pix = 2*(self.nlev_t)**2\n",
    "        self.use_ql = False #The nbody power spectrum is matched with trainingdata\n",
    "        self.wf_batch_size = 100 #The number of maps to fit\n",
    "        mask128 = (imageio.imread(\"masks/mask1_128.png\")[:, :, 0]/255).astype(float)\n",
    "        self.mask = mask128 #np.ones((self.nx, self.nx))\n",
    "        \n",
    "        #Pre-trained flow parameters\n",
    "        self.flow_n_layers = 16\n",
    "        self.flow_hidden = [12, 12]\n",
    "        self.trained_flow_dir = 'pretrained_flows/'\n",
    "        \n",
    "params = Parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61d7273-ed8f-417e-9314-205a084cc0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = flow_architecture.SimpleNormal(torch.zeros((params.nx, params.nx)), torch.ones((params.nx, params.nx)))\n",
    "\n",
    "layers = flow_architecture.make_flow1_affine_layers(lattice_shape=(params.nx, params.nx),\n",
    "                                                    n_layers=params.flow_n_layers, hidden_sizes=params.flow_hidden,\n",
    "                                                    kernel_size=[3, 3, 3], torch_device=device, padding_mode='circular')\n",
    "model = {'layers': layers, 'prior': prior}\n",
    "\n",
    "checkpoint = torch.load(params.trained_flow_dir+'dict_periodic')\n",
    "model['layers'].load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93102e2-1135-4f26-be2b-282539e7ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_np = np.load('sample_test_data/128px_true_maps_periodic.npy')\n",
    "np.save(save_dir + 'true_maps', y_true_np)\n",
    "\n",
    "y_pred_np = utilities.add_noise(y_true_np, std=params.noise_fac) * params.mask\n",
    "np.save(save_dir + 'masked_maps', y_pred_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a05b76-6a29-491c-848b-6f59f693783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = np.min(y_true_np)\n",
    "vmax = 11\n",
    "figsize = (4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efc027e-9020-4c8f-97d4-9060614d3778",
   "metadata": {},
   "outputs": [],
   "source": [
    "utilities.imshow(y_true_np[0], vmin=vmin, vmax=vmax, title='Truth', figsize=figsize, axis=False, colorbar=False, file_name=save_dir+'truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87af32fc-53f2-4818-ad21-08508a35560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "utilities.imshow(y_pred_np[0], vmin=vmin, vmax=vmax, title='Masked', figsize=figsize, axis=False, colorbar=False, file_name=save_dir+'masked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207aa212-85e7-4314-8198-3e249e85536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true        = torch.tensor(y_true_np, requires_grad=True,  dtype=torch.float32).to(device)\n",
    "y_pred_nograd = torch.tensor(y_pred_np, requires_grad=False, dtype=torch.float32).to(device)\n",
    "y_pred_flow = [None] * params.wf_batch_size\n",
    "for n in range(params.wf_batch_size):\n",
    "    y_pred_flow[n]   = torch.tensor(np.expand_dims(y_pred_np[n], 0), requires_grad=True,  dtype=torch.float32).to(device)\n",
    "y_pred_wf = [None] * params.wf_batch_size\n",
    "for n in range(params.wf_batch_size):\n",
    "    y_pred_wf[n] = torch.tensor(np.expand_dims(y_pred_np[n], 0), requires_grad=True,  dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c93a13a-5f49-445a-9900-cb133a8b15e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossfunctions = losses.Lossfunctions(params, cl_theo_ell=cl_theo_ell, cl_theo=cl_theo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789e11c3-8c16-45ae-9cc0-b642249cc7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list_flow = []\n",
    "J2_ave_list_flow = []\n",
    "J2_map_list_flow = [None] * params.wf_batch_size\n",
    "loss_list_wf = []\n",
    "J2_ave_list_wf = []\n",
    "J2_map_list_wf = [None] * params.wf_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf60a71d-3597-4809-9fe3-1a2d30f36c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_flow = []\n",
    "for n in range(params.wf_batch_size):\n",
    "    optimizer_flow.append(torch.optim.Adam([y_pred_flow[n]], lr=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03ddb41-6b83-4b31-9e76-90935fffcda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(y_pred_nograd, y_pred, optimizer, steps, loss_list, J2_ave_list, J2_map_list, use_flow, print_freq=100):\n",
    "    for i in range(steps):\n",
    "        loss_ave = 0\n",
    "        J2_ave = 0\n",
    "        \n",
    "        for n in range(params.wf_batch_size):\n",
    "            optimizer[n].zero_grad()\n",
    "            if use_flow:\n",
    "                loss_1, loss_2 = lossfunctions.loss_wiener_J3_flow(y_pred_nograd[n], y_pred[n], prior, model['layers'])\n",
    "            else:\n",
    "                loss_1, loss_2 = lossfunctions.loss_wiener_J3(y_pred_nograd[n], y_pred[n])\n",
    "            loss = loss_1 + loss_2\n",
    "            loss.backward()\n",
    "            optimizer[n].step()\n",
    "            loss_ave += loss.cpu().detach().numpy() / params.wf_batch_size\n",
    "            J2_map_list[n] = lossfunctions.loss_J2(y_true[n], y_pred[n]).cpu().detach().numpy()\n",
    "            J2_ave += J2_map_list[n] / params.wf_batch_size\n",
    "            \n",
    "            \n",
    "        loss_list.append(loss_ave)\n",
    "        J2_ave_list.append(J2_ave)\n",
    "        if i % print_freq == 0: print(\"step =\", i, \"loss =\", loss_ave, \"J2 =\", J2_ave)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5935493f-4709-4f23-bee0-1076c257e627",
   "metadata": {},
   "source": [
    "## Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a17ffe6-02a8-4c13-9fd4-9ee9b4dc1e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize(y_pred_nograd, y_pred_flow, optimizer_flow, 300, loss_list_flow, J2_ave_list_flow, J2_map_list_flow, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d9bfa9-77fb-461a-89b5-448c2d358702",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(params.wf_batch_size):\n",
    "    for g in optimizer_flow[0].param_groups:\n",
    "        g['lr'] = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c33ae75-bbe3-4173-a3b4-4d67edec44bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize(y_pred_nograd, y_pred_flow, optimizer_flow, 1000, loss_list_flow, J2_ave_list_flow, J2_map_list_flow, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ac38ca-7981-4801-9da4-2038466b464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "utilities.plot_lists(loss_list_flow[:], title='Flow loss', file_name=save_dir+'flow_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e53d81-4d09-43ed-87a5-d922229347e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "utilities.plot_lists(J2_ave_list_flow, title='Flow J2', file_name=save_dir+'flow_J2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21f7009-3776-4d3b-b74e-95cd33581047",
   "metadata": {},
   "outputs": [],
   "source": [
    "J2_ave_list_flow[-1]/(128*128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef801fd8-412a-4df1-84eb-0fcb0fbb7ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_flow_np = y_pred_flow[0].cpu().detach().numpy()\n",
    "utilities.imshow(y_pred_flow_np[0], title='Optimized map with flow prior',\n",
    "                 vmin=vmin, vmax=vmax, figsize=figsize, axis=False, colorbar=False, file_name=save_dir+'flow_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79961ce-8fc0-46a9-951c-a5b35fb90e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(save_dir+'/y_pred_flow_np', y_pred_flow_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac0f116-bde2-403b-88ee-bdb76dcdbd46",
   "metadata": {},
   "source": [
    "## Weiner filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805cefc5-d14d-4346-9068-f7fc13b5b691",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_wf = []\n",
    "for n in range(params.wf_batch_size):\n",
    "    optimizer_wf.append(torch.optim.Adam([y_pred_wf[n]], lr=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08071d74-2b40-410c-a4c2-ca7f8a2cd593",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize(y_pred_nograd, y_pred_wf, optimizer_wf, 3000, loss_list_wf, J2_ave_list_wf, J2_map_list_wf, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8a70a7-064a-4002-8faa-2b85ff112571",
   "metadata": {},
   "outputs": [],
   "source": [
    "utilities.plot_lists(loss_list_wf[:], title='WF loss', file_name=save_dir+'wf_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6e7721-50bb-44fb-8b1b-fcc6904834dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "utilities.plot_lists(J2_ave_list_wf, title='WF J2', file_name=save_dir+'wf_J2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc1090b-fad4-4256-862b-b9dc65d0e83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_wf_np = y_pred_wf[0].cpu().detach().numpy()\n",
    "utilities.imshow(y_pred_wf_np[0], title='Optimized map with Wiener filtering',\n",
    "                 vmin=vmin, vmax=vmax, figsize=figsize, axis=False, colorbar=False, file_name=save_dir+'/wf_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931bc09c-b4a1-471b-86bf-ac4a7541a958",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(save_dir+'y_pred_wf_np', y_pred_wf_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f0d978-238c-4189-aff2-c49013b56be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_flow_cc = torch.zeros((params.wf_batch_size, params.nx, params.nx))\n",
    "for n in range(params.wf_batch_size):\n",
    "    y_pred_flow_cc[n, :, :] = y_pred_flow[n]\n",
    "    \n",
    "y_pred_wf_cc = torch.zeros((params.wf_batch_size, params.nx, params.nx))\n",
    "for n in range(params.wf_batch_size):\n",
    "    y_pred_wf_cc[n, :, :] = y_pred_wf[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38db9ef9-4c84-4bdf-8322-df385e55b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_flow_cc_np = utilities.grab(y_pred_flow_cc)\n",
    "np.save(save_dir + 'flow_maps', y_pred_flow_cc_np)\n",
    "\n",
    "y_pred_wf_cc_np = utilities.grab(y_pred_wf_cc)\n",
    "np.save(save_dir + 'wf_maps', y_pred_wf_cc_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0ac2f2-5bae-4495-a80f-5187ee20a8a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
