{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146b5009-fad1-431f-b8b0-5a256aac54ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import Pk_library as PKL\n",
    "import scipy.ndimage\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import utilities\n",
    "import flow_architecture\n",
    "import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb50d8d-e848-4c44-85d8-c756b70965fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "float_dtype = np.float32\n",
    "torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "device_id = 2\n",
    "torch.cuda.set_device(device_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ba5420-4056-41cf-8062-b04bc36de001",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"nbody_384px_mask_1p0_flow/\"\n",
    "if not os.path.exists(save_dir): os.makedirs(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0b3e89-ab57-4eb6-959f-1097b45946f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_theo_ell = np.load('sample_test_data/384px_cl_theo_ell.npy')\n",
    "cl_theo = np.load('sample_test_data/384px_cl_theo.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d091ef-11a2-4298-94d8-d59eb3d84004",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parameters():\n",
    "    def __init__(self):\n",
    "        #Data parameters\n",
    "        self.nx = 128\n",
    "        self.dx = 0.00018425707547169813\n",
    "        \n",
    "        #Fitting parameters\n",
    "        self.nlev_t = 1.0\n",
    "        self.noise_fac = self.nlev_t\n",
    "        self.noise_pix = 2*(self.nlev_t)**2\n",
    "        self.use_ql = False #The nbody power spectrum is matched with trainingdata\n",
    "        self.wf_batch_size = 100 #The number of maps to fit\n",
    "        \n",
    "        mask512 = (imageio.imread(\"masks/mask2_512.png\")[19:485, 19:485, 0]/255).astype(float)\n",
    "        self.mask = scipy.ndimage.zoom(mask512, 384/(485-19), order=0)\n",
    "        mask_patch_0 = utilities.make_small_maps_from_big_map(torch.tensor(self.mask,  dtype=torch.float32), 128)\n",
    "        mask_patch_1 = utilities.make_small_maps_from_big_map(torch.tensor(self.mask,  dtype=torch.float32), 128, displace=1)\n",
    "        mask_patch_2 = utilities.make_small_maps_from_big_map(torch.tensor(self.mask,  dtype=torch.float32), 128, displace=2)\n",
    "        mask_patch_3 = utilities.make_small_maps_from_big_map(torch.tensor(self.mask,  dtype=torch.float32), 128, displace=3)\n",
    "        self.mask_patches = torch.cat((mask_patch_0, mask_patch_1, mask_patch_2, mask_patch_3), axis=0)\n",
    "        \n",
    "        #Pre-trained flow parameters\n",
    "        self.flow_n_layers = 16\n",
    "        self.flow_hidden = [12, 12]\n",
    "        self.trained_flow_dir = 'pretrained_flows/'\n",
    "        \n",
    "params = Parameters()\n",
    "\n",
    "n_maps = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec0d3da-14a9-407a-b59c-37d28502f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(params.mask)\n",
    "plt.colorbar()\n",
    "print(params.mask.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61d7273-ed8f-417e-9314-205a084cc0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = flow_architecture.SimpleNormal(torch.zeros((params.nx, params.nx)), torch.ones((params.nx, params.nx)))\n",
    "\n",
    "layers = flow_architecture.make_flow1_affine_layers(lattice_shape=(params.nx, params.nx),\n",
    "                                                    n_layers=params.flow_n_layers, hidden_sizes=params.flow_hidden,\n",
    "                                                    kernel_size=[3, 3, 3], torch_device=device, padding_mode='zeros')\n",
    "model = {'layers': layers, 'prior': prior}\n",
    "\n",
    "checkpoint = torch.load(params.trained_flow_dir+'dict_nonperiodic')\n",
    "model['layers'].load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93102e2-1135-4f26-be2b-282539e7ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_np = np.load('sample_test_data/384px_true_map.npy')\n",
    "y_true_np = (y_true_np - np.mean(y_true_np)) / np.std(y_true_np)\n",
    "np.save(save_dir + 'true_maps', y_true_np)\n",
    "\n",
    "y_pred_np = utilities.add_noise(y_true_np, std=params.noise_fac) * params.mask\n",
    "np.save(save_dir + 'masked_maps', y_pred_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a05b76-6a29-491c-848b-6f59f693783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = np.min(y_true_np)\n",
    "vmax = 11\n",
    "figsize = (6, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efc027e-9020-4c8f-97d4-9060614d3778",
   "metadata": {},
   "outputs": [],
   "source": [
    "utilities.imshow(y_true_np[0], vmin=vmin, vmax=vmax, title='Truth', figsize=figsize, axis=False, colorbar=False, file_name=save_dir+'truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87af32fc-53f2-4818-ad21-08508a35560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "utilities.imshow(y_pred_np[0], vmin=vmin, vmax=vmax, title='Masked', figsize=figsize, axis=False, colorbar=False, file_name=save_dir+'masked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db343c64-4e14-443f-ab95-247b5ebf4077",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_0 = utilities.make_small_maps_from_big_map(torch.tensor(y_pred_np[0],  dtype=torch.float32), 128)\n",
    "y_pred_1 = utilities.make_small_maps_from_big_map(torch.tensor(y_pred_np[0],  dtype=torch.float32), 128, displace=1)\n",
    "y_pred_2 = utilities.make_small_maps_from_big_map(torch.tensor(y_pred_np[0],  dtype=torch.float32), 128, displace=2)\n",
    "y_pred_3 = utilities.make_small_maps_from_big_map(torch.tensor(y_pred_np[0],  dtype=torch.float32), 128, displace=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6e4cb5-33ce-44a0-817b-ff034f5fdcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_all = torch.cat((y_pred_0, y_pred_1, y_pred_2, y_pred_3), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207aa212-85e7-4314-8198-3e249e85536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true        = torch.tensor(y_true_np, requires_grad=True,  dtype=torch.float32).to(device)\n",
    "y_pred_nograd = torch.tensor(y_pred_all, requires_grad=False, dtype=torch.float32).to(device)\n",
    "y_pred_flow = [None] * n_maps\n",
    "for n in range(n_maps):\n",
    "    y_pred_flow[n] = torch.tensor(torch.unsqueeze(y_pred_all[n], 0), requires_grad=True).to(device)\n",
    "y_pred_wf = [None] * params.wf_batch_size\n",
    "for n in range(1):\n",
    "    y_pred_wf[n] = torch.tensor(np.expand_dims(y_pred_np[n], 0), requires_grad=True,  dtype=torch.float32).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c93a13a-5f49-445a-9900-cb133a8b15e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossfunctions = losses.Lossfunctions(params, cl_theo_ell=cl_theo_ell, cl_theo=cl_theo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789e11c3-8c16-45ae-9cc0-b642249cc7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_list_flow = []\n",
    "J2_ave_list_flow = []\n",
    "J2_map_list_flow = [None] * params.wf_batch_size\n",
    "loss_list_wf = []\n",
    "J2_ave_list_wf = []\n",
    "J2_map_list_wf = [None] * params.wf_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf60a71d-3597-4809-9fe3-1a2d30f36c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_flow = []\n",
    "for n in range(36):\n",
    "    optimizer_flow.append(torch.optim.Adam([y_pred_flow[n]], lr=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03ddb41-6b83-4b31-9e76-90935fffcda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(y_pred_nograd, y_pred, optimizer, steps, loss_list, J2_ave_list, J2_map_list, use_flow, print_freq=100):\n",
    "    for i in range(steps):\n",
    "        loss_ave = 0\n",
    "        J2_ave = 0\n",
    "        \n",
    "        for n in range(n_maps):\n",
    "            optimizer[n].zero_grad()\n",
    "            if use_flow:\n",
    "                loss_1, loss_2 = lossfunctions.loss_wiener_J3_flow_patching(y_pred_nograd[n], y_pred[n], prior, model['layers'], patch_id=n)\n",
    "            else:\n",
    "                loss_1, loss_2 = lossfunctions.loss_wiener_J3(y_pred_nograd[n], y_pred[n])\n",
    "            loss = loss_1 + loss_2\n",
    "            loss.backward()\n",
    "            optimizer[n].step()\n",
    "            loss_ave += loss.cpu().detach().numpy() / params.wf_batch_size\n",
    "            \n",
    "        loss_list.append(loss_ave)\n",
    "        if i % print_freq == 0: print(\"step =\", i, \"loss =\", loss_ave, \"J2 =\", J2_ave)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5935493f-4709-4f23-bee0-1076c257e627",
   "metadata": {},
   "source": [
    "## Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a17ffe6-02a8-4c13-9fd4-9ee9b4dc1e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize(y_pred_nograd, y_pred_flow, optimizer_flow, 3, loss_list_flow, J2_ave_list_flow, J2_map_list_flow, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d9bfa9-77fb-461a-89b5-448c2d358702",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(params.wf_batch_size):\n",
    "    for g in optimizer_flow[0].param_groups:\n",
    "        g['lr'] = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c33ae75-bbe3-4173-a3b4-4d67edec44bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize(y_pred_nograd, y_pred_flow, optimizer_flow, 10, loss_list_flow, J2_ave_list_flow, J2_map_list_flow, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ac38ca-7981-4801-9da4-2038466b464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "utilities.plot_lists(loss_list_flow[:], title='Flow loss', file_name=save_dir+'flow_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef801fd8-412a-4df1-84eb-0fcb0fbb7ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_flow_np = y_pred_flow[0].cpu().detach().numpy()\n",
    "utilities.imshow(y_pred_flow_np[0], title='Optimized map with flow prior',\n",
    "                 vmin=vmin, vmax=vmax, figsize=figsize, axis=False, colorbar=False, file_name=save_dir+'flow_result')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79961ce-8fc0-46a9-951c-a5b35fb90e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(save_dir+'y_pred_flow_np', y_pred_flow_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f0d978-238c-4189-aff2-c49013b56be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_flow_cc = torch.zeros((n_maps, params.nx, params.nx))\n",
    "for n in range(n_maps):\n",
    "    y_pred_flow_cc[n, :, :] = y_pred_flow[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38db9ef9-4c84-4bdf-8322-df385e55b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_flow_cc_np = utilities.grab(y_pred_flow_cc)\n",
    "np.save(save_dir + 'flow_maps', y_pred_flow_cc_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0ac2f2-5bae-4495-a80f-5187ee20a8a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
